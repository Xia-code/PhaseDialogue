<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Autonomous dialogue generation based on phase boundary detection within continuous motion for domestic robot</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Autonomous dialogue generation based on phase boundary detection within continuous motion for domestic robot" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/PhaseDialogue/" />
<meta property="og:url" content="http://localhost:4000/PhaseDialogue/" />
<meta property="og:site_name" content="Autonomous dialogue generation based on phase boundary detection within continuous motion for domestic robot" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Autonomous dialogue generation based on phase boundary detection within continuous motion for domestic robot" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"Autonomous dialogue generation based on phase boundary detection within continuous motion for domestic robot","name":"Autonomous dialogue generation based on phase boundary detection within continuous motion for domestic robot","url":"http://localhost:4000/PhaseDialogue/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/PhaseDialogue/assets/css/style.css?v=">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/PhaseDialogue/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Autonomous dialogue generation based on phase boundary detection within continuous motion for domestic robot</h1>
      <h2 class="project-tagline">
      
        <br>Sixia Li, Tamon Miyake, Tetsuya Ogata, Shigeki Sugano, Shogo Okada
      
      
        <br>Japan Advanced Institute of Science and Technology and Waseda University
      </h2>
      <div class="project-statusline">
      
        <br>(Accepted by 34th IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN 2025))
      </div>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <!-- Logo -->
<p><img src="/PhaseDialogue/assets/images/logo.png" alt="Logo" style="position: absolute; top: 0px; right: 0px; width: 280px; height: auto; z-index: 1000;" /></p>

<!-- First line -->
<div style="text-align: center;">
  <span style="color: #215F9A; font-size: 36px;">Let the robot tell you what it is doing in a continous motion.</span>
</div>

<style>
  .media-row {
    display: flex;
    justify-content: space-between;
    gap: 20px;
    margin: 40px 0;
  }

  .media-item {
    width: 48%;
    text-align: center;
  }

  .media-item video, .media-item img {
    max-width: 100%;
    height: auto;
    line-height: auto;
    border: 1px solid #ccc;
    border-radius: 6px;
  }

  .caption {
    height: 3em; 
    line-height: 1.5em;
    overflow: hidden;
    font-size: 18px;
    color: #555;
    margin: 8px 0;
  }
</style>

<!-- Comparison videos -->
<div class="media-row">
  <!-- Left -->
  <div class="media-item">
    <div class="caption">Robot without our system, saying nothing during a continous motion.</div>
    <video controls="">
      <source src="/PhaseDialogue/assets/videos/no_dialogue.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
    <img src="/PhaseDialogue/assets/images/compare_without.png" alt="Pic1" />
    <div class="caption">The user doesn't know what robot is doing in a continous motion.</div>
  </div>

  <!-- Right -->
  <div class="media-item">
    <div class="caption">Robot with our system, automounously speaking to the user when phase changes in a continous motion.</div>
    <video controls="">
      <source src="/PhaseDialogue/assets/videos/has_dialogue.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
    <img src="/PhaseDialogue/assets/images/compare_with.png" alt="Pic2" />
    <div class="caption">The user can know what robot is doing in a continous motion.</div>
  </div>
</div>

<h2 id="abstract">Abstract</h2>

<p>Dialogue generation plays a key role in responding to user and providing transparency in motion execution in human-robot interaction. As motion planning is generally performed in terms of discrete motions, previous studies have focused on dialogue generation at the boundaries between motions. Recently, continuous motion generation was proposed to enable adapting actions to unique characteristics of the objects for domestic robots. Since a continuous motion generally involves physical and nonphysical phases, providing dialogues when the phase changes is crucial for decreasing users’ anxiety and guaranteeing safety. However, continuous motions lack clear phase boundaries, posing challenges for dialogue generation between phases. For this problem, we segmented continuous motions into discrete phases, and constructed a system to enable the robot to autonomously generate dialogues by detecting phase boundaries. To do so, we built phase estimation models using robot sensor data and designed system modules. Specifically, we collected data in the scenario of a robot assisting to lift the user up from bed. We segmented the continuous motion into three phases based on the user’s posture and whether the robot applied force to the human. The best phase estimation model achieved a macro F1 score of 0.894, demonstrating that phases can be estimated from sensor data. The evaluation results of our system demonstrated that the system accurately detects phase boundaries and generates appropriate dialogues corresponding to phases. Furthermore, we conducted simulations with a user agent to investigate system behaviors when the phase estimation was incorrect. The results suggested that explicitly stating the phase is important for avoiding misunderstandings and safety issues.</p>

<h2 id="system-structure">System Structure</h2>

<p>Our system is consisted of phase etimation model, phase change detector, prompt generator, LLM, and TTS modules. The phase estimation model estimate phases based on robot sensor data. The phase change detector then check whether the motion phase changes, and prompt generator, LLM, and TTS generate dialogues corresopnding to phases if phase changes detected.</p>

<figure style="text-align: center;">
  <img src="/PhaseDialogue/assets/images/system_structure.png" alt="Pic_system" style="max-width: 70%; height: auto;" />
  <figcaption>System structure.</figcaption>
</figure>

<h2 id="phase-estimation-modeling">Phase estimation modeling</h2>

<p>We segment the continous motion of assisting the user to lift up from the bed into three phases. Then we use SVM, DNN (Feedforward layers), and LSTM to model phase estimation using sensor data including torque, angle, touch, and differences between two frames of these sensor data.</p>

<figure style="text-align: center;">
  <img src="/PhaseDialogue/assets/images/phase_segmentation.png" alt="Pic_phases" style="max-width: 70%; height: auto;" />
  <!-- <figcaption>Three phases in the continous motion.</figcaption> -->
</figure>

<p>Experimental results show that phases can be estimated from sensor data effectively. The following table shows the best combiation of sensor data for each model, the ■ indicates the sensor data included in the best combination.</p>

<figure style="text-align: center;">
  <img src="/PhaseDialogue/assets/images/phase_results.png" alt="Pic_phase_results" style="max-width: 55%; height: auto;" />
  <!-- <figcaption>Phase estimation results.</figcaption> -->
</figure>

<h2 id="dialogue-generation-corresponding-to-phases">Dialogue generation corresponding to phases</h2>
<p>Results of dialogue simulation in generating dialogue corresponding to phase show that our system is able to generate appropriate dialogues that introducing the robot intent for the subsequential motion phase.</p>

<figure style="text-align: center;">
  <img src="/PhaseDialogue/assets/images/dialogue_simulation.png" alt="Pic_phase_results" style="max-width: 45%; height: auto;" />
  <!-- <figcaption>Phase estimation results.</figcaption> -->
</figure>

<h2 id="findings-when-phase-etimation-is-incorrect">Findings when phase etimation is incorrect</h2>
<p>Results of dialogue simulation between the robot and the user when <strong>phase estimation is incorrect</strong> suggest that explicitly mentioning about phase is important to avoid user misunderstanding and safety issues.</p>

<figure style="text-align: center;">
  <img src="/PhaseDialogue/assets/images/phase_incorrect.png" alt="Pic_phase_incorrect" style="max-width: 70%; height: auto;" />
  <!-- <figcaption>Three phases in the continous motion.</figcaption> -->
</figure>

<h2 id="bibtex">BibTex</h2>
<p>Waiting for conference processing.</p>

<h2 id="acknowledgement">Acknowledgement</h2>
<p>This research is supported by JST Moonshot R&amp;D program (JPMJMS2031).</p>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
